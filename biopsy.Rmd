---
title: "Decision Trees - Breast Cancer Biopsy Data"
output:
  pdf_document: default
  html_notebook: default
---

Decision trees are a Machine Learning method that is underrated, because of its (usually) low accuracy.  

Although, its explanatory power can be very good to explore problems and gain new insights.
Let's see this example, with data from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg. He assessed biopsies of breast tumours for 699 patients up to 15 July 1992. (R Documentation, 2019)

```{r code, echo=F,message=F,warning=FALSE}
# loading cancer biopsy data:
library(MASS)
library(rpart)
library(rpart.plot)

# loading all columns, except ID
cancer <- MASS::biopsy[,2:11]

# renamiing cols:
colnames(cancer) <- c("tumor.thickness",
                     "uniform.cell.size",
                     "uniform.cell.shape",
                     "margin.adhesion",
                     "epitelial.cell.size",
                     "bare.nuclei", # 16 NAs here -- we will replace them by medians
                     "bland.chromatin",
                     "normal.nucleoli",
                     "mitoses",
                     "malignant"
                     )
# recoding target(dependent) variable malignant to 0 or 1
cancer$malignant <- as.numeric(as.factor(cancer$malignant))-1


# NA Fills - Checking NA Values:
#View(cancer[is.na(cancer$bare.nuclei),])

# only 2 of 14 values are malignant.  We will fill with the bare.nuclei median value for benign tumors

#filling missing values using vector operations (more efficient than for loops!)
cancer[is.na(cancer$bare.nuclei),]$bare.nuclei <- median(cancer[cancer$malignant == 0,]$bare.nuclei, na.rm = T)

#building train-test splits:
#generating test and train data - Data selected randomly with a 80/20 split
x <- cancer
trainIndex  <- sample(1:nrow(cancer), 0.8 * nrow(cancer))
train <- cancer[trainIndex,]
test <- cancer[-trainIndex,]
  
# Modelling Decision Tree:
mytree <- rpart(malignant ~ tumor.thickness+uniform.cell.size+uniform.cell.shape+margin.adhesion+
                  epitelial.cell.size+bare.nuclei+bland.chromatin+normal.nucleoli+mitoses, data = train, 
                method = "class") #, control=rpart.control(minsplit=50, cp=0.013))

# Plotting Decision Tree:
rpart.plot(mytree, type = 1, extra=1)


```

## Interpreting results:

All branches for the left side are the "yes" answer for the group dividing question. "no" for the right.
The numbers inside each cell are the total of benign (left side) and malignant (right side)

1. It is well known that non-uniformity of cell sizes and shapes are correlated with malignancy

2. The presence of a dual population of epithelial and myoepithelial cells and of numerous bare nuclei within a breast aspirate is generally indicative of a benign lesion. (McCluggage et al, 1997)

3. Chromatin alterations are also suggestive of malignancy. The bigger bland.chromatin, higher the probability of malignancy

One interesting conclusion from the model:  Tumor samples with non-uniform cell sizes, non-uniform shapes and low number of bare nuclei are ~ 20x more likely to be malignant.

## Testing Model Parameters:

```{r accuracy,echo=T}
# TESTING & EVALUATING MODEL:

# testing predictions on the model:
t_pred <- predict(mytree,test,type="class")
t <- test['malignant']

#building a confusion matrix
confMat <- table(test$malignant,t_pred)

print('Confusion Matrix:')
print(confMat)

# getting model accuracy:
accuracy <- sum(diag(confMat))/sum(confMat)
print('model accuracy (in %):')
print(accuracy) # 0.9285714 -> 92.8%  Not bad!!!
```

We have a confusion matrix which shows that our model got 5 false positives and 5 false negative results, for a total of 140 testing samples.

In terms of success metrics, it means that the model has an accuracy of 92.8%.

Find the source code for this report at https://git.io/fh7qR
